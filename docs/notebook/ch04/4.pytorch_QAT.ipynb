{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 环境配置\n",
    "\n",
    "首先，我们导入必须的环境，数据集和model使用和前几章相同的minist数据集和LeNet网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f14fe352af0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.quantization\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from utils import LeNet,train,evaluate,get_model_size,get_model_flops,MiB\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 构建模型和数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "    \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "        \n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "\n",
    "        x = x.contiguous().view(x.shape[0], -1)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet()#.to(device=device)\n",
    "print(model)\n",
    "# 加载模型的状态字典\n",
    "# checkpoint = torch.load('../ch02/model.pt')\n",
    "checkpoint = torch.load('./model.pt')\n",
    "\n",
    "# 加载状态字典到模型\n",
    "model.load_state_dict(checkpoint)\n",
    "fp32_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置归一化\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# 获取数据集\n",
    "# train_dataset = datasets.MNIST(root='../ch02/data/mnist', train=True, download=True, transform=transform)  \n",
    "# test_dataset = datasets.MNIST(root='../ch02/data/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集\n",
    "train_dataset = datasets.MNIST(root='./data/mnist', train=True, download=True, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root='./data/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集\n",
    "# 设置DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 验证 FP32 模型的精度以及模型大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8597c81c4547a3b32f0ac0e461e5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 model has accuracy=97.99000%\n",
      "fp32 model has size=0.17 MiB\n"
     ]
    }
   ],
   "source": [
    "fp32_model_accuracy = evaluate(fp32_model, test_loader)\n",
    "fp32_model_size = get_model_size(fp32_model)\n",
    "print(f\"fp32 model has accuracy={fp32_model_accuracy:.5f}%\")\n",
    "print(f\"fp32 model has size={fp32_model_size/MiB:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 将模型转化为量化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qnnpack', 'none', 'fbgemm']\n"
     ]
    }
   ],
   "source": [
    "backend = torch.backends.quantized.supported_engines #运行时可以使用这句命令检查自己支持的后端\n",
    "print(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(\n",
       "    1, 6, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(\n",
       "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(\n",
       "    in_features=256, out_features=120, bias=True\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(\n",
       "    in_features=120, out_features=84, bias=True\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu4): ReLU()\n",
       "  (fc3): Linear(\n",
       "    in_features=84, out_features=10, bias=True\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将模型量化为QAT模型\n",
    "quant_model = copy.deepcopy(model)\n",
    "quant_model.qconfig = torch.quantization.get_default_qat_qconfig(backend[-1])\n",
    "torch.quantization.prepare_qat(quant_model, inplace=True)\n",
    "print(quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到上边的model中添加了FakeQuantize这个函数，这个函数就是用来进行模拟量化的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 验证量化模型的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039dee0dd4844709ba10d959df84d789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quant model has accuracy=98.37000%\n"
     ]
    }
   ],
   "source": [
    "quant_model_accuracy = evaluate(quant_model, test_loader)\n",
    "print(f\"quant model has accuracy={quant_model_accuracy:.5f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 对量化后的模型进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b9a9a831f84fdbbc6a865a5851d421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=938.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e01505b2bd4caa91d7a783158315ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 0 Accuracy 98.34% / Best Accuracy: 98.34%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2187b48d4b4175b437535acd4b25b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=938.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65a122e87a749f6bea93dac4b4251ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 1 Accuracy 98.32% / Best Accuracy: 98.34%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6538b5e345a4449c8122eb2a9b558899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=938.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef10de5f3e384cee9dd1f24c200ddf55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 2 Accuracy 98.28% / Best Accuracy: 98.34%\n"
     ]
    }
   ],
   "source": [
    "num_finetune_epochs = 3 #   这里一般微调5～10个epoch\n",
    "optimizer = torch.optim.SGD(quant_model.parameters(), lr=0.001, momentum=0.9) #学习率调低一些\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_finetune_epochs)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_accuracy = 0\n",
    "epoch = num_finetune_epochs\n",
    "while epoch > 0:\n",
    "    train(quant_model, train_loader, criterion, optimizer, scheduler)\n",
    "    model_accuracy = evaluate(quant_model, test_loader)\n",
    "    is_best = model_accuracy > best_accuracy\n",
    "    best_accuracy = max(model_accuracy, best_accuracy)\n",
    "    print(f'        Epoch {num_finetune_epochs-epoch} Accuracy {model_accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')\n",
    "    epoch -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 将量化模型转化为量化部署模型并验证其精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里重新定义一个验证函数。因为模型在量化后，输入输出也需要进行量化。具体添加的内容如下：\n",
    "    outputs = dequant(outputs)\n",
    "    inputs = quant(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "quant = torch.quantization.QuantStub() \n",
    "dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "def evaluate_quant(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  extra_preprocess = None\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "  \n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    # inputs = inputs.to('mps')\n",
    "    if extra_preprocess is not None:\n",
    "        for preprocess in extra_preprocess:\n",
    "            inputs = quant(inputs)\n",
    "            inputs = preprocess(inputs)\n",
    "\n",
    "    # targets = targets.to('mps')\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "    # print(outputs)\n",
    "    outputs = dequant(outputs)\n",
    "    # Convert logits to class indices\n",
    "    # print(outputs)\n",
    "    outputs = outputs.to(\"cpu\")\n",
    "    # outputs = outputs.argmax(dim=1)\n",
    "    outputs=torch.max(outputs,1)[1]\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将量化训练后的模型中的Fake节点去掉，这样可以得到一个真正的int8模型。下边模型中的节点算子都变成了Quantized算子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): QuantizedConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.16204923391342163, zero_point=36)\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.3756241202354431, zero_point=54)\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): QuantizedLinear(in_features=256, out_features=120, scale=0.28476396203041077, zero_point=53, qscheme=torch.per_channel_affine)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): QuantizedLinear(in_features=120, out_features=84, scale=0.2204333394765854, zero_point=55, qscheme=torch.per_channel_affine)\n",
      "  (relu4): ReLU()\n",
      "  (fc3): QuantizedLinear(in_features=84, out_features=10, scale=0.28054389357566833, zero_point=60, qscheme=torch.per_channel_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.quantization.convert(quant_model, inplace=True)\n",
    "print(quant_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证全int8模型的精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到全int8模型的精度和量化训练时的最后一个epoch的精度几乎一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e19869e7b64fb38e9a23c24d25cc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='eval', max=157.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_quant model has accuracy=98.37000%\n"
     ]
    }
   ],
   "source": [
    "final_quant_model_accuracy = evaluate_quant(quant_model, test_loader)\n",
    "print(f\"final_quant model has accuracy={final_quant_model_accuracy:.5f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
