{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关库和网络\n",
    "\n",
    "使用 `res32x4` 去蒸馏 `res8x4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 教师网络和学生网络\n",
    "from nets.resnet import resnet32x4, resnet8x4\n",
    "# 知识蒸馏 KD 的损失函数\n",
    "from loss.kd import loss\n",
    "\n",
    "# TensorBoard\n",
    "Train_Info = \"KD : Res32x4 To Res8x4\"\n",
    "writer = SummaryWriter(comment=Train_Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子, 从而可以复现\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU, 将 '1' 里的数字改为您的设备上的gpu编号\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 4               # temperature : 知识蒸馏中的温度\n",
    "ALPHA = 0.1         # alpha : hard_loss(硬损失交叉熵)的loss weight \n",
    "BETA = 0.9          # beta : soft_loss(软损失KL散度)的loss weight\n",
    "N = 100             # num_classes : 类别数\n",
    "EPOCH = 20          # epoch : 训练轮数\n",
    "BATCH_SIZE = 128    # batch_size : 批处理大小 \n",
    "LR = 0.05           # learning_rate : 初试学习率\n",
    "\n",
    "# 其余的超参数, 例如 : 优化器中的 momentum, weight_decay, milestones, gamma 等一般情况下很少变动.\n",
    "# 当EPOCH变化的时候, milestones也要随之变化. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载教师模型, 以及定义学生网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res32x4 = resnet32x4(num_classes=N)\n",
    "ckpt = torch.load(\"checkpoints/teacher/ckpt_epoch_240.pth\", map_location='cpu')\n",
    "res32x4.load_state_dict(ckpt[\"model\"])\n",
    "res32x4 = nn.DataParallel(res32x4).cuda()\n",
    "res32x4.eval()\n",
    "\n",
    "res8x4 = resnet8x4(num_classes=N)\n",
    "res8x4 = torch.nn.DataParallel(res8x4).cuda()\n",
    "\n",
    "teacher_net = res32x4\n",
    "student_net = res8x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集\n",
    "第一次使用会先进行下载, 如果下载的很慢, 可以手动下载数据集然后拖入到 data 文件夹下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集并预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # 先四周填充0，在把图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),     # 图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)), #R,G,B每层的归一化用到的均值和方差\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "# 训练数据集\n",
    "# num_workers一般情况下取决于 cpu 的性能\n",
    "trainset = torchvision.datasets.CIFAR100(root=DATA_PATH, train=True, download=True, transform=transform_train) \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)   \n",
    "# 测试数据集\n",
    "testset = torchvision.datasets.CIFAR100(root=DATA_PATH, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "\n",
    "一般在各种论文中 cifar-100 数据集上的 `epoch` 都会选择设置为 `240`\n",
    "\n",
    "其对应的 `milestones`的值为 `[150, 180, 210]`\n",
    "\n",
    "这里仅做展示, 所有 `epoch` 设置了 `40`,  `milestones`的值为 `[15, 25, 35]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(student_net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25, 35], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train函数和Test函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别定义训练集和测试集上的最佳Acc, 使用 global 修饰为全局变量, 然后再训练期间更新\n",
    "best_train_acc = 0\n",
    "best_test_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(epoch):\n",
    "    global best_train_acc\n",
    "\n",
    "    # 设置学生模型为训练模式\n",
    "    student_net.train()\n",
    "\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 使用 tqdm 包装 trainloader 以显示进度条\n",
    "    with tqdm(trainloader, desc=f\"Training Epoch {epoch}\", total=len(trainloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits_student, _ = student_net(inputs)\n",
    "            with torch.no_grad():\n",
    "                logits_teacher, _ = teacher_net(inputs)\n",
    "\n",
    "            # 硬损失\n",
    "            ce_loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "            # 软损失\n",
    "            kd_loss = loss(logits_student, logits_teacher, temperature=T)\n",
    "            total_loss = ALPHA * ce_loss + BETA * kd_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "            _, predicted = logits_student.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # 更新 TensorBoard\n",
    "            writer.add_scalar('Train/Accuracy', 100. * correct / total, batch_idx + (epoch - 1) * 782)\n",
    "            writer.add_scalar('Train/Loss', total_loss.item(), batch_idx + (epoch - 1) * 782)\n",
    "\n",
    "            # 使用 set_postfix 更新进度条的后缀\n",
    "            pbar.set_postfix(loss=train_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "    # 如果当前训练集上的准确率高于 best_test_acc，则更新 best_test_acc\n",
    "    acc = 100 * correct / total\n",
    "    if acc > best_train_acc:\n",
    "        best_train_acc = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, epoch):\n",
    "    global best_test_acc\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 使用 tqdm 包装 testloader 以显示进度条\n",
    "        with tqdm(testloader, desc=f\"Testing Epoch {epoch}\", total=len(testloader)) as pbar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                logits_student, _ = net(inputs)\n",
    "\n",
    "                loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = logits_student.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                # 在 tqdm 进度条的后缀中显示当前损失和准确率\n",
    "                pbar.set_postfix(loss=test_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "                # 更新 TensorBoard\n",
    "                writer.add_scalar('Test/Accuracy', 100. * correct / total, batch_idx + (epoch - 1) * 157)\n",
    "                writer.add_scalar('Test/Loss', loss.item(), batch_idx + (epoch - 1) * 157)\n",
    "\n",
    "        # 计算当前测试集上的准确率\n",
    "        acc = 100. * correct / total\n",
    "\n",
    "        # 如果当前测试集上的准确率高于 best_test_acc，则更新 best_test_acc\n",
    "        # 并且将学生模型保存下来\n",
    "        if acc > best_test_acc:\n",
    "            print('Saving..')\n",
    "            torch.save(student_net, 'checkpoints/student/kd_res8x4.pth')\n",
    "            best_test_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 391/391 [01:05<00:00,  5.99it/s, acc=10.1%, loss=8.75]\n",
      "Testing Epoch 1: 100%|██████████| 79/79 [00:06<00:00, 13.00it/s, acc=14.0%, loss=3.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 391/391 [00:51<00:00,  7.57it/s, acc=19.9%, loss=7.69]\n",
      "Testing Epoch 2: 100%|██████████| 79/79 [00:06<00:00, 12.45it/s, acc=18.0%, loss=4.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 391/391 [00:51<00:00,  7.58it/s, acc=28.5%, loss=6.84]\n",
      "Testing Epoch 3: 100%|██████████| 79/79 [00:06<00:00, 12.30it/s, acc=26.4%, loss=3.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 391/391 [00:52<00:00,  7.48it/s, acc=36.2%, loss=6.18]\n",
      "Testing Epoch 4: 100%|██████████| 79/79 [00:06<00:00, 11.85it/s, acc=34.3%, loss=2.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 391/391 [00:52<00:00,  7.40it/s, acc=41.6%, loss=5.71]\n",
      "Testing Epoch 5: 100%|██████████| 79/79 [00:06<00:00, 12.99it/s, acc=37.0%, loss=2.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 391/391 [00:51<00:00,  7.59it/s, acc=45.8%, loss=5.36]\n",
      "Testing Epoch 6: 100%|██████████| 79/79 [00:06<00:00, 11.31it/s, acc=34.7%, loss=3.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 391/391 [00:53<00:00,  7.30it/s, acc=49.4%, loss=5.05]\n",
      "Testing Epoch 7: 100%|██████████| 79/79 [00:06<00:00, 12.15it/s, acc=44.5%, loss=2.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 391/391 [00:54<00:00,  7.15it/s, acc=52.2%, loss=4.82]\n",
      "Testing Epoch 8: 100%|██████████| 79/79 [00:06<00:00, 12.31it/s, acc=47.3%, loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 391/391 [00:51<00:00,  7.66it/s, acc=54.5%, loss=4.64]\n",
      "Testing Epoch 9: 100%|██████████| 79/79 [00:06<00:00, 12.63it/s, acc=37.1%, loss=3.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 391/391 [00:52<00:00,  7.44it/s, acc=56.7%, loss=4.47]\n",
      "Testing Epoch 10: 100%|██████████| 79/79 [00:06<00:00, 12.72it/s, acc=46.0%, loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 391/391 [00:51<00:00,  7.66it/s, acc=58.2%, loss=4.33]\n",
      "Testing Epoch 11: 100%|██████████| 79/79 [00:05<00:00, 13.35it/s, acc=50.8%, loss=2.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 391/391 [00:50<00:00,  7.69it/s, acc=59.6%, loss=4.22]\n",
      "Testing Epoch 12: 100%|██████████| 79/79 [00:06<00:00, 12.33it/s, acc=51.1%, loss=2.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 391/391 [00:51<00:00,  7.66it/s, acc=60.6%, loss=4.13]\n",
      "Testing Epoch 13: 100%|██████████| 79/79 [00:06<00:00, 11.76it/s, acc=52.1%, loss=2.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 391/391 [00:50<00:00,  7.82it/s, acc=61.3%, loss=4.07]\n",
      "Testing Epoch 14: 100%|██████████| 79/79 [00:06<00:00, 12.75it/s, acc=53.1%, loss=2.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 391/391 [00:51<00:00,  7.64it/s, acc=62.1%, loss=3.98]\n",
      "Testing Epoch 15: 100%|██████████| 79/79 [00:06<00:00, 13.16it/s, acc=51.2%, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 391/391 [00:49<00:00,  7.95it/s, acc=69.5%, loss=3.35]\n",
      "Testing Epoch 16: 100%|██████████| 79/79 [00:06<00:00, 12.28it/s, acc=65.2%, loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 391/391 [00:52<00:00,  7.45it/s, acc=71.6%, loss=3.17]\n",
      "Testing Epoch 17: 100%|██████████| 79/79 [00:06<00:00, 12.60it/s, acc=65.2%, loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 391/391 [00:51<00:00,  7.61it/s, acc=72.3%, loss=3.1] \n",
      "Testing Epoch 18: 100%|██████████| 79/79 [00:06<00:00, 13.09it/s, acc=65.8%, loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 391/391 [00:50<00:00,  7.67it/s, acc=72.6%, loss=3.06]\n",
      "Testing Epoch 19: 100%|██████████| 79/79 [00:06<00:00, 12.95it/s, acc=66.2%, loss=1.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 391/391 [00:52<00:00,  7.47it/s, acc=73.4%, loss=3.01]\n",
      "Testing Epoch 20: 100%|██████████| 79/79 [00:06<00:00, 11.53it/s, acc=66.3%, loss=1.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCH + 1) :\n",
    "    train(epoch)\n",
    "    test(student_net, epoch)\n",
    "\n",
    "    # 更新学习率\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KD : Res32x4 To Res8x4\n",
      "best_Train_Acc =  73.41\n",
      "best_Test_Acc =  66.31\n"
     ]
    }
   ],
   "source": [
    "print(Train_Info)\n",
    "print('best_Train_Acc = ', best_train_acc)\n",
    "print('best_Test_Acc = ', best_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.29' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.28' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "/home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/huasi/miniconda3/envs/dkd/lib/python3.8/site-packages/tensorboard_data_server/bin/server)\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.14.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 启动 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
